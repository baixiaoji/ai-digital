"""
AI Digital - æ™ºèƒ½ç¬”è®°æ£€ç´¢ç³»ç»Ÿ
FastAPI ä¸»å…¥å£
"""
import sys
from pathlib import Path
from contextlib import asynccontextmanager

import uvicorn
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from services.indexer import IndexerService
from services.retriever import RetrieverService
from config import settings, logger

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    logger.info("ğŸš€ å¯åŠ¨ AI Digital åç«¯æœåŠ¡...")
    
    # åˆå§‹åŒ–ç´¢å¼•æœåŠ¡
    app.state.indexer = IndexerService()
    app.state.retriever = RetrieverService(app.state.indexer)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ„å»ºç´¢å¼•
    if not app.state.indexer.is_index_exists():
        logger.info("ğŸ“š é¦–æ¬¡è¿è¡Œï¼Œå¼€å§‹æ„å»ºç´¢å¼•...")
        await app.state.indexer.build_index()
        logger.info("âœ… ç´¢å¼•æ„å»ºå®Œæˆ")
    else:
        logger.info("âœ… åŠ è½½ç°æœ‰ç´¢å¼•")
        await app.state.indexer.load_index()
    
    yield
    
    # å…³é—­æœåŠ¡
    logger.info("ğŸ›‘ å…³é—­æœåŠ¡...")
    await app.state.indexer.close()


# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="AI Digital API",
    description="æ™ºèƒ½ç¬”è®°æ£€ç´¢ç³»ç»Ÿ API",
    version="1.0.0",
    lifespan=lifespan
)

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.server.cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/")
async def root():
    """å¥åº·æ£€æŸ¥"""
    return {
        "service": "AI Digital",
        "status": "running",
        "version": "1.0.0"
    }


@app.get("/api/status")
async def get_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    indexer = app.state.indexer
    stats = await indexer.get_stats()
    
    return {
        "indexed_files": stats["total_files"],
        "total_chunks": stats["total_chunks"],
        "last_update": stats["last_update"],
        "index_size_mb": stats["index_size_mb"]
    }


@app.post("/api/search")
async def search(query: str, local_ratio: float = 0.8):
    """
    æ™ºèƒ½æ£€ç´¢æ¥å£
    
    Args:
        query: ç”¨æˆ·é—®é¢˜
        local_ratio: æœ¬åœ°ç»“æœå æ¯” (0-1)
    """
    try:
        retriever = app.state.retriever
        results = await retriever.hybrid_search(query, local_ratio)
        
        return {
            "query": query,
            "results": results,
            "total": len(results)
        }
    except Exception as e:
        logger.error(f"æœç´¢å¤±è´¥: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={"error": str(e)}
        )


@app.post("/api/chat")
async def chat_stream(query: str, local_ratio: float = 0.8):
    """
    æµå¼å¯¹è¯æ¥å£ï¼ˆæš‚æ—¶è¿”å›æ™®é€š JSONï¼Œåç»­æ”¹ä¸º SSEï¼‰
    
    Args:
        query: ç”¨æˆ·é—®é¢˜
        local_ratio: æœ¬åœ°ç»“æœå æ¯”
    """
    from fastapi.responses import StreamingResponse
    
    async def event_generator():
        # å¿…é¡»åœ¨å‡½æ•°å¼€å¤´å¯¼å…¥ï¼
        import json
        from config import logger
        
        retriever = app.state.retriever
        
        logger.info(f"ğŸ” æ”¶åˆ°æŸ¥è¯¢è¯·æ±‚: '{query}' (local_ratio={local_ratio})")
        
        # è®¡ç®—æœ¬åœ°å’Œç½‘ç»œçš„ top_k
        total_results = 20
        local_k = int(total_results * local_ratio)
        network_k = int(total_results * (1 - local_ratio))
        
        logger.info(f"ğŸ“Š æ£€ç´¢ç­–ç•¥: æœ¬åœ°={local_k}æ¡, ç½‘ç»œ={network_k}æ¡ (æ€»è®¡={total_results})")
        
        # Step 1: å·¥å…·è°ƒç”¨ - æœ¬åœ°æ£€ç´¢
        if local_k > 0:
            logger.info(f"ğŸ” å¼€å§‹æœ¬åœ°æ£€ç´¢ (top_k={local_k})")
            yield f'data: {json.dumps({"type": "tool_call", "tool": "local_search", "status": "running"})}\n\n'
            local_results = await retriever.local_search(query, top_k=local_k)
            logger.info(f"âœ… æœ¬åœ°æ£€ç´¢å®Œæˆ: {len(local_results)}æ¡ç»“æœ")
            # æ‰“å°å‰ 5 æ¡æœ¬åœ°å¬å›ç»“æœï¼ŒåŒ…å«å†…å®¹ä¸å…ƒæ•°æ®é¢„è§ˆï¼ˆä½¿ç”¨å±æ€§è®¿é—®ï¼‰
            logger.info(
                f"ğŸ” æœ¬åœ°å¬å›ç»“æœç¤ºä¾‹: "
                f"{[{'content': r.content[:50], 'metadata': {k: v for k, v in r.to_dict().items() if k != 'content'}} for r in local_results[:5]]}"
            )

            yield f'data: {json.dumps({"type": "tool_call", "tool": "local_search", "status": "completed", "count": len(local_results)})}\n\n'
        else:
            logger.info("â­ï¸  è·³è¿‡æœ¬åœ°æ£€ç´¢ (local_k=0)")
            local_results = []
        
        # Step 2: å·¥å…·è°ƒç”¨ - ç½‘ç»œæœç´¢
        if network_k > 0:
            logger.info(f"ğŸŒ å¼€å§‹ç½‘ç»œæœç´¢ (top_k={network_k})")
            yield f'data: {json.dumps({"type": "tool_call", "tool": "web_search", "status": "running"})}\n\n'
            web_results = await retriever.web_search_async(query, top_k=network_k)
            logger.info(f"âœ… ç½‘ç»œæœç´¢å®Œæˆ: {len(web_results)}æ¡ç»“æœ")
            yield f'data: {json.dumps({"type": "tool_call", "tool": "web_search", "status": "completed", "count": len(web_results)})}\n\n'
        else:
            logger.info("â­ï¸  è·³è¿‡ç½‘ç»œæœç´¢ (network_k=0)")
            web_results = []
        
        # Step 3: åˆå¹¶ç»“æœ
        all_results = local_results + web_results
        logger.info(f"ğŸ“¦ ç»“æœæ±‡æ€»: æœ¬åœ°={len(local_results)}, ç½‘ç»œ={len(web_results)}, æ€»è®¡={len(all_results)}")
        
        # Step 4: ä½¿ç”¨ LLM æµå¼ç”Ÿæˆç­”æ¡ˆå¹¶ç›´æ¥å‘é€
        logger.info("ğŸ¤– å¼€å§‹æµå¼ç”Ÿæˆç­”æ¡ˆ...")
        async for chunk in retriever.format_answer(query, all_results):
            # ç›´æ¥å‘é€ LLM ç”Ÿæˆçš„æ–‡æœ¬ç‰‡æ®µ
            if chunk:
                yield f'data: {json.dumps({"type": "text", "content": chunk}, ensure_ascii=False)}\n\n'
        
        # Step 5: å‘é€å¼•ç”¨
        citations = retriever.format_citations(all_results)
        logger.info(f"ğŸ“š å‘é€å¼•ç”¨æ•°æ®: {len(citations)}ä¸ªæ¥æº")
        yield f'data: {json.dumps({"type": "citations", "data": citations}, ensure_ascii=False)}\n\n'
        
        # Step 6: ç»“æŸæ ‡è®°
        logger.info("âœ… æµå¼å“åº”å®Œæˆ")
        yield f'data: {json.dumps({"type": "done"})}\n\n'
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream"
    )


@app.post("/api/rebuild-index")
async def rebuild_index():
    """é‡å»ºç´¢å¼•"""
    try:
        indexer = app.state.indexer
        await indexer.build_index()
        return {"status": "success", "message": "ç´¢å¼•é‡å»ºå®Œæˆ"}
    except Exception as e:
        logger.error(f"ç´¢å¼•é‡å»ºå¤±è´¥: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={"error": str(e)}
        )


if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=settings.server.backend_port,
        reload=True,
        log_level="info"
    )
