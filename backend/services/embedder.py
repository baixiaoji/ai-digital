"""
å‘é‡åŒ–æœåŠ¡
è°ƒç”¨ AI Builders Embedding API
"""
import asyncio
from typing import List

import httpx
from tqdm import tqdm

from config import settings, logger
from database.embedding_cache import EmbeddingCache


class EmbedderService:
    """å‘é‡åŒ–æœåŠ¡"""
    
    def __init__(self):
        self.api_base = settings.embedding.api_base
        self.model = settings.embedding.model
        self.api_key = settings.api_key
        self.batch_size = settings.embedding.batch_size
        self.dimension = settings.embedding.dimension
        
        # åˆå§‹åŒ–ç¼“å­˜
        self.cache = EmbeddingCache()
        self._cache_initialized = False
        
        # åˆ†ç¦»è¿æ¥/è¯»å†™è¶…æ—¶ï¼Œé¿å…å¤§å“åº”ä½“è¶…æ—¶
        timeout_config = httpx.Timeout(
            connect=30.0,   # è¿æ¥è¶…æ—¶ï¼š30 ç§’
            read=180.0,     # è¯»å–è¶…æ—¶ï¼š180 ç§’ï¼ˆå¤§å“åº”ä½“ï¼‰
            write=60.0,     # å†™å…¥è¶…æ—¶ï¼š60 ç§’
            pool=10.0       # è¿æ¥æ± è¶…æ—¶ï¼š10 ç§’
        )
        
        self.client = httpx.AsyncClient(
            base_url=self.api_base,
            headers={
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            },
            timeout=timeout_config,  # ä½¿ç”¨åˆ†ç¦»çš„è¶…æ—¶é…ç½®
            limits=httpx.Limits(max_connections=20, max_keepalive_connections=10)
        )
    
    async def embed_texts(self, texts: List[str], show_progress: bool = True) -> List[List[float]]:
        """
        æ‰¹é‡å‘é‡åŒ–æ–‡æœ¬ï¼ˆå¹¶å‘ç‰ˆæœ¬ + ç¼“å­˜ï¼‰
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
        
        Returns:
            å‘é‡åˆ—è¡¨
        """
        # ç¡®ä¿ç¼“å­˜å·²åˆå§‹åŒ–
        if not self._cache_initialized:
            await self.cache.initialize()
            self._cache_initialized = True
        
        all_embeddings = []
        
        # åˆ†æ‰¹å¤„ç†
        batches = [texts[i:i + self.batch_size] for i in range(0, len(texts), self.batch_size)]
        
        # å¹¶å‘å‚æ•°ï¼ˆä»é…ç½®è¯»å–ï¼‰
        max_concurrent = getattr(settings.embedding, 'max_concurrent', 6)
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def embed_with_semaphore(batch, batch_idx):
            """å¸¦ä¿¡å·é‡çš„å‘é‡åŒ–ï¼ˆå«ç¼“å­˜é€»è¾‘ï¼‰"""
            async with semaphore:
                embeddings = await self._embed_batch_with_cache(batch)
                return batch_idx, embeddings
        
        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        tasks = [embed_with_semaphore(batch, i) for i, batch in enumerate(batches)]
        
        # æ‰§è¡Œå¹¶å‘è¯·æ±‚
        if show_progress:
            results = []
            with tqdm(total=len(batches), desc="å‘é‡åŒ–") as pbar:
                for coro in asyncio.as_completed(tasks):
                    result = await coro
                    results.append(result)
                    pbar.update(1)
        else:
            results = await asyncio.gather(*tasks)
        
        # æŒ‰æ‰¹æ¬¡é¡ºåºæ’åº
        results.sort(key=lambda x: x[0])
        
        # å±•å¹³åµŒå¥—åˆ—è¡¨
        for _, embeddings in results:
            all_embeddings.extend(embeddings)
        
        return all_embeddings
    
    async def _embed_batch(self, texts: List[str], max_retries: int = 3) -> List[List[float]]:
        """
        å‘é‡åŒ–å•ä¸ªæ‰¹æ¬¡ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        
        Returns:
            å‘é‡åˆ—è¡¨
        """
        for attempt in range(max_retries):
            try:
                logger.debug(f"å‘é€ API è¯·æ±‚: {len(texts)} ä¸ªæ–‡æœ¬ (å°è¯• {attempt+1}/{max_retries})")
                response = await self.client.post(
                    "/v1/embeddings",
                    json={
                        "model": self.model,
                        "input": texts
                    }
                    # ä½¿ç”¨å…¨å±€ timeout é…ç½®ï¼ˆå·²åœ¨ client åˆå§‹åŒ–æ—¶è®¾ç½®ï¼‰
                )
                response.raise_for_status()
                
                result = response.json()
                
                # æå–å‘é‡ï¼ˆæŒ‰ index æ’åºï¼‰
                embeddings_data = sorted(result['data'], key=lambda x: x['index'])
                embeddings = [item['embedding'] for item in embeddings_data]
                
                logger.debug(f"âœ… æˆåŠŸè·å– {len(embeddings)} ä¸ªå‘é‡")
                return embeddings
            
            except httpx.HTTPStatusError as e:
                if e.response.status_code == 429:  # Rate limit
                    wait_time = (attempt + 1) * 5  # æŒ‡æ•°é€€é¿ï¼š5s, 10s, 15s
                    logger.warning(f"âš ï¸ è§¦å‘é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time}s åé‡è¯•...")
                    await asyncio.sleep(wait_time)
                    continue
                logger.error(f"âŒ API è¯·æ±‚å¤±è´¥: {e.response.status_code}")
                logger.error(f"å“åº”å†…å®¹: {e.response.text[:200]}")
                if attempt == max_retries - 1:
                    raise
            except httpx.TimeoutException as e:
                logger.warning(f"âš ï¸ API è¯·æ±‚è¶…æ—¶ï¼Œé‡è¯•ä¸­...")
                if attempt == max_retries - 1:
                    logger.error(f"âŒ æœ€ç»ˆè¶…æ—¶: {str(e)}")
                    raise
                await asyncio.sleep(2)
            except Exception as e:
                logger.error(f"âŒ å‘é‡åŒ–å¤±è´¥: {type(e).__name__}: {str(e)}")
                if attempt == max_retries - 1:
                    raise
                await asyncio.sleep(1)
        
        raise RuntimeError(f"å‘é‡åŒ–å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡")
    
    async def _embed_batch_with_cache(self, texts: List[str]) -> List[List[float]]:
        """
        å¸¦ç¼“å­˜çš„æ‰¹é‡å‘é‡åŒ–
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
        
        Returns:
            å‘é‡åˆ—è¡¨
        """
        # 1. å°è¯•ä»ç¼“å­˜è·å–
        cached_embeddings = await self.cache.get_batch(texts, self.model)
        
        # 2. æ‰¾å‡ºæœªå‘½ä¸­çš„æ–‡æœ¬
        uncached_indices = [i for i, emb in enumerate(cached_embeddings) if emb is None]
        uncached_texts = [texts[i] for i in uncached_indices]
        
        # 3. å¦‚æœå…¨éƒ¨å‘½ä¸­ï¼Œç›´æ¥è¿”å›
        if not uncached_texts:
            logger.debug(f"âœ… ç¼“å­˜å‘½ä¸­: {len(texts)}/{len(texts)}")
            return cached_embeddings
        
        # 4. è°ƒç”¨ API è·å–æœªå‘½ä¸­çš„å‘é‡
        logger.debug(f"ğŸ“Š ç¼“å­˜å‘½ä¸­: {len(texts) - len(uncached_texts)}/{len(texts)}, éœ€è¦è¯·æ±‚: {len(uncached_texts)}")
        new_embeddings = await self._embed_batch(uncached_texts)
        
        # 5. å­˜å…¥ç¼“å­˜
        await self.cache.set_batch(uncached_texts, self.model, new_embeddings)
        
        # 6. åˆå¹¶ç»“æœ
        result = cached_embeddings[:]
        for i, idx in enumerate(uncached_indices):
            result[idx] = new_embeddings[i]
        
        return result
    
    async def embed_query(self, query: str) -> List[float]:
        """
        å‘é‡åŒ–å•ä¸ªæŸ¥è¯¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
        
        Returns:
            æŸ¥è¯¢å‘é‡
        """
        embeddings = await self.embed_texts([query], show_progress=False)
        return embeddings[0]
    
    async def close(self):
        """å…³é—­ HTTP å®¢æˆ·ç«¯å’Œç¼“å­˜"""
        await self.client.aclose()
        if self._cache_initialized:
            await self.cache.close()


# æµ‹è¯•ä»£ç 
async def test_embedder():
    """æµ‹è¯•å‘é‡åŒ–æœåŠ¡"""
    embedder = EmbedderService()
    
    # æµ‹è¯•å•ä¸ªæ–‡æœ¬
    text = "å¦‚ä½•ä¼˜åŒ– Python ä»£ç æ€§èƒ½ï¼Ÿ"
    vector = await embedder.embed_query(text)
    
    print(f"æ–‡æœ¬: {text}")
    print(f"å‘é‡ç»´åº¦: {len(vector)}")
    print(f"å‘é‡ç¤ºä¾‹ï¼ˆå‰10ç»´ï¼‰: {vector[:10]}")
    
    # æµ‹è¯•æ‰¹é‡æ–‡æœ¬
    texts = [
        "Python æ€§èƒ½ä¼˜åŒ–æŠ€å·§",
        "ä½¿ç”¨ Cython åŠ é€Ÿä»£ç ",
        "å¤šè¿›ç¨‹å¹¶å‘å¤„ç†"
    ]
    
    vectors = await embedder.embed_texts(texts, show_progress=True)
    print(f"\næ‰¹é‡å‘é‡åŒ–å®Œæˆ: {len(vectors)} ä¸ªå‘é‡")
    
    await embedder.close()


if __name__ == "__main__":
    asyncio.run(test_embedder())
