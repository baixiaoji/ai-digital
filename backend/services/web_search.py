"""
ç½‘ç»œæœç´¢æœåŠ¡
ä½¿ç”¨ DuckDuckGo API (æ–°ç‰ˆ ddgs SDK)
"""
import asyncio
from typing import List, Dict
from datetime import datetime

try:
    from ddgs import DDGS
except ImportError:
    # å…¼å®¹æ—§åŒ…å
    try:
        from duckduckgo_search import DDGS
    except ImportError:
        from duckduckgo_search import AsyncDDGS as DDGS

import httpx
from bs4 import BeautifulSoup

from config import logger, settings


class WebSearchService:
    """ç½‘ç»œæœç´¢æœåŠ¡"""
    
    def __init__(self):
        self.cache_dir = settings.storage.cache_dir
        self.max_content_length = 1000  # ç½‘é¡µå†…å®¹æœ€å¤§é•¿åº¦
    
    async def search(self, query: str, max_results: int = 5) -> List[Dict]:
        """
        æœç´¢ç½‘ç»œå†…å®¹ï¼ˆä½¿ç”¨æ–°ç‰ˆ DuckDuckGo SDKï¼‰
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            max_results: æœ€å¤§ç»“æœæ•°
        
        Returns:
            [{"title": ..., "url": ..., "snippet": ..., "content": ...}, ...]
        """
        try:
            # è¾“å…¥éªŒè¯
            if not query or not query.strip():
                logger.warning("æœç´¢æŸ¥è¯¢ä¸ºç©º")
                return []
            
            # é™åˆ¶æŸ¥è¯¢é•¿åº¦å’Œç»“æœæ•°
            query = query.strip()[:500]
            max_results = min(max(1, max_results), 10)
            
            logger.info(f"ğŸŒ å¼€å§‹ç½‘ç»œæœç´¢: {query}")
            
            # ä½¿ç”¨æ–°ç‰ˆ DDGS APIï¼ˆåŒæ­¥è½¬å¼‚æ­¥ï¼‰
            results = await self._ddgs_search(query, max_results)
            
            if not results:
                logger.warning(f"ç½‘ç»œæœç´¢æ— ç»“æœ: {query}")
                return []
            
            # æŠ“å–é¡µé¢å†…å®¹ï¼ˆå¹¶å‘ï¼‰
            tasks = [self._fetch_content(item) for item in results]
            results = await asyncio.gather(*tasks)
            
            logger.info(f"âœ… ç½‘ç»œæœç´¢å®Œæˆï¼Œè¿”å› {len(results)} æ¡ç»“æœ")
            return results
        
        except Exception as e:
            logger.error(f"âŒ ç½‘ç»œæœç´¢å¤±è´¥: {str(e)}")
            return []
    
    async def _ddgs_search(self, query: str, max_results: int) -> List[Dict]:
        """
        è°ƒç”¨ DuckDuckGo æœç´¢ï¼ˆåŒæ­¥ API è½¬å¼‚æ­¥ï¼‰
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            max_results: æœ€å¤§ç»“æœæ•°
        
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        def _sync_search():
            """åŒæ­¥æœç´¢é€»è¾‘"""
            results = []
            
            try:
                # å°è¯•å…¨çƒæœç´¢
                with DDGS() as ddgs:
                    search_results = ddgs.text(
                        query,
                        max_results=max_results,
                        region="wt-wt",
                        safesearch="moderate"
                    )
                    
                    # ddgs.text() è¿”å›ç”Ÿæˆå™¨ï¼Œéœ€è¦è½¬ä¸ºåˆ—è¡¨
                    for result in search_results:
                        results.append({
                            "title": result.get("title", ""),
                            "url": result.get("href", ""),
                            "snippet": result.get("body", ""),
                            "source": "web",
                            "fetched_at": datetime.now().isoformat()
                        })
                
                # å¦‚æœæ— ç»“æœï¼Œå°è¯•ç¾å›½åŒºåŸŸ
                if not results:
                    with DDGS() as ddgs:
                        search_results = ddgs.text(
                            query,
                            max_results=max_results,
                            region="us-en",
                            safesearch="moderate"
                        )
                        
                        for result in search_results:
                            results.append({
                                "title": result.get("title", ""),
                                "url": result.get("href", ""),
                                "snippet": result.get("body", ""),
                                "source": "web",
                                "fetched_at": datetime.now().isoformat()
                            })
            
            except Exception as e:
                logger.error(f"DuckDuckGo æœç´¢å¼‚å¸¸: {str(e)}")
            
            return results
        
        # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥ä»£ç ï¼ˆé¿å…é˜»å¡å¼‚æ­¥äº‹ä»¶å¾ªç¯ï¼‰
        loop = asyncio.get_event_loop()
        results = await loop.run_in_executor(None, _sync_search)
        
        return results
    
    async def _fetch_content(self, item: Dict) -> Dict:
        """
        æŠ“å–ç½‘é¡µå†…å®¹
        
        Args:
            item: æœç´¢ç»“æœé¡¹
        
        Returns:
            è¡¥å……äº† content å­—æ®µçš„ç»“æœ
        """
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(item["url"])
                response.raise_for_status()
                
                # è§£æ HTML
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # ç§»é™¤è„šæœ¬å’Œæ ·å¼
                for script in soup(["script", "style"]):
                    script.decompose()
                
                # æå–æ–‡æœ¬
                text = soup.get_text()
                
                # æ¸…ç†æ–‡æœ¬
                lines = (line.strip() for line in text.splitlines())
                chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
                text = ' '.join(chunk for chunk in chunks if chunk)
                
                # æˆªæ–­å†…å®¹
                if len(text) > self.max_content_length:
                    text = text[:self.max_content_length] + "..."
                
                item["content"] = text
                logger.debug(f"âœ… æŠ“å–æˆåŠŸ: {item['url']}")
        
        except Exception as e:
            logger.warning(f"âš ï¸ æŠ“å–å¤±è´¥ {item['url']}: {str(e)}")
            # å¤±è´¥æ—¶ä½¿ç”¨ snippet
            item["content"] = item.get("snippet", "")
        
        return item


# æµ‹è¯•ä»£ç 
async def test_web_search():
    """æµ‹è¯•ç½‘ç»œæœç´¢"""
    service = WebSearchService()
    
    query = "Python performance optimization"
    results = await service.search(query, max_results=3)
    
    print(f"æœç´¢: {query}")
    print(f"ç»“æœæ•°: {len(results)}\n")
    
    for idx, result in enumerate(results, 1):
        print(f"{idx}. {result['title']}")
        print(f"   URL: {result['url']}")
        print(f"   å†…å®¹: {result['content'][:100]}...")
        print()


if __name__ == "__main__":
    asyncio.run(test_web_search())
