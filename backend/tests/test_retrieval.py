"""
æœ¬åœ°æ£€ç´¢åŠŸèƒ½å•å…ƒæµ‹è¯•
æµ‹è¯•æŸ¥è¯¢: "æ£€ç´¢ç¬”è®°ä¸­AIå…¬å¸" å’Œ "Logseqçš„ç”¨æ³•"
"""
import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from services.retriever import RetrieverService
from services.indexer import IndexerService
from config import settings
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def test_local_retrieval():
    """æµ‹è¯•æœ¬åœ°æ£€ç´¢åŠŸèƒ½"""
    
    # åˆå§‹åŒ–ç»„ä»¶
    logger.info("=" * 60)
    logger.info("ğŸ” å¼€å§‹æœ¬åœ°æ£€ç´¢å•å…ƒæµ‹è¯•")
    logger.info("=" * 60)
    
    # åˆå§‹åŒ– indexerï¼ˆåŒ…å«æ‰€æœ‰ä¾èµ–ï¼‰
    indexer = IndexerService()
    
    # æ£€æŸ¥ç´¢å¼•çŠ¶æ€
    logger.info("\nğŸ“Š ç´¢å¼•çŠ¶æ€æ£€æŸ¥:")
    logger.info(f"  - å‘é‡æ•°æ®åº“è·¯å¾„: {settings.storage.vector_index}")
    logger.info(f"  - å…ƒæ•°æ®æ•°æ®åº“è·¯å¾„: {settings.storage.metadata_db}")
    
    # æ£€æŸ¥å‘é‡æ•°é‡
    vector_count = indexer.vector_store.get_vector_count()
    logger.info(f"  - å‘é‡æ€»æ•°: {vector_count}")
    
    if vector_count == 0:
        logger.error("âŒ å‘é‡æ•°æ®åº“ä¸ºç©ºï¼è¯·å…ˆè¿è¡Œç´¢å¼•æ„å»º")
        return
    
    # æ£€æŸ¥å…ƒæ•°æ®æ•°é‡
    documents = indexer.metadata_store.list_documents()
    logger.info(f"  - æ–‡æ¡£æ€»æ•°: {len(documents)}")
    if documents:
        logger.info(f"  - å‰ 3 ä¸ªæ–‡æ¡£æ ‡é¢˜: {[doc.get('title', 'N/A') for doc in documents[:3]]}")
    
    # åˆ›å»ºæ£€ç´¢å™¨
    retriever = RetrieverService(indexer)
    
    # æµ‹è¯•æŸ¥è¯¢åˆ—è¡¨
    test_queries = [
        "æ£€ç´¢ç¬”è®°ä¸­AIå…¬å¸",
        "Logseqçš„ç”¨æ³•"
    ]
    
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ” å¼€å§‹æµ‹è¯•æŸ¥è¯¢")
    logger.info("=" * 60)
    
    for i, query in enumerate(test_queries, 1):
        logger.info(f"\n{'*' * 60}")
        logger.info(f"æµ‹è¯•æŸ¥è¯¢ #{i}: {query}")
        logger.info(f"{'*' * 60}")
        
        try:
            # 1. æµ‹è¯• query embedding
            logger.info("\nğŸ”¹ æ­¥éª¤ 1: ç”ŸæˆæŸ¥è¯¢å‘é‡")
            query_embedding = await indexer.embedder.embed_texts([query])
            logger.info(f"  âœ… æŸ¥è¯¢å‘é‡ç»´åº¦: {len(query_embedding[0])}")
            logger.info(f"  âœ… å‘é‡å‰ 5 ä¸ªå€¼: {query_embedding[0][:5]}")
            
            # 2. æµ‹è¯•å‘é‡æœç´¢
            logger.info("\nğŸ”¹ æ­¥éª¤ 2: æ‰§è¡Œå‘é‡æœç´¢ (top_k=10)")
            vector_results = indexer.vector_store.search(query_embedding[0], top_k=10)
            logger.info(f"  ğŸ“Š å‘é‡æœç´¢è¿”å›: {len(vector_results)} æ¡ç»“æœ")
            
            if vector_results:
                for j, (chunk_id, score) in enumerate(vector_results[:3], 1):
                    # æ³¨æ„ï¼šsearch è¿”å› (chunk_id, score) å…ƒç»„
                    logger.info(f"    #{j} Chunk ID={chunk_id}, Score={score:.4f}")
                    # ç®€å•æ£€æŸ¥ chunk æ˜¯å¦å­˜åœ¨ï¼ˆå…ƒæ•°æ®åº“æŸ¥è¯¢è¾ƒå¤æ‚ï¼Œè·³è¿‡è¯¦ç»†å†…å®¹ï¼‰
            else:
                logger.warning("  âš ï¸ å‘é‡æœç´¢è¿”å› 0 ç»“æœ")
            
            # 3. æµ‹è¯•æœ¬åœ°æ£€ç´¢
            logger.info("\nğŸ”¹ æ­¥éª¤ 3: æ‰§è¡Œæœ¬åœ°æ£€ç´¢ (top_k=5)")
            results = await retriever.local_search(query, top_k=5)
            logger.info(f"  ğŸ“Š æœ¬åœ°æ£€ç´¢è¿”å›: {len(results)} æ¡ç»“æœ")
            
            if results:
                logger.info(f"\n  ğŸ¯ æ£€ç´¢ç»“æœè¯¦æƒ…:")
                for j, result in enumerate(results, 1):
                    # results æ˜¯ SearchResult å¯¹è±¡åˆ—è¡¨
                    logger.info(f"    --- ç»“æœ #{j} ---")
                    logger.info(f"      æ¥æº: {result.source}")
                    logger.info(f"      æ–‡æ¡£: {result.file_path}")
                    logger.info(f"      ç›¸ä¼¼åº¦: {result.score:.4f}")
                    logger.info(f"      æ ‡é¢˜: {result.title}")
                    content_preview = result.content[:100]
                    logger.info(f"      å†…å®¹é¢„è§ˆ: {content_preview}...")
            else:
                logger.error(f"  âŒ æœ¬åœ°æ£€ç´¢è¿”å› 0 ç»“æœï¼")
                
                # è¿›ä¸€æ­¥è¯Šæ–­
                logger.info("\n  ğŸ”§ è¯Šæ–­ä¿¡æ¯:")
                logger.info(f"    - å‘é‡æ•°æ®åº“æ˜¯å¦ä¸ºç©º: {vector_count == 0}")
                logger.info(f"    - å…ƒæ•°æ®æ•°æ®åº“æ˜¯å¦ä¸ºç©º: {len(documents) == 0}")
                logger.info(f"    - æŸ¥è¯¢å‘é‡æ˜¯å¦æœ‰æ•ˆ: {len(query_embedding[0]) == 1536}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç›¸ä¼¼åº¦é˜ˆå€¼é—®é¢˜
                logger.info("\n  ğŸ”§ æµ‹è¯•æ›´å®½æ¾çš„é˜ˆå€¼ (top_k=20):")
                loose_results = indexer.vector_store.search(query_embedding[0], top_k=20)
                logger.info(f"    æ‰¾åˆ° {len(loose_results)} æ¡å€™é€‰ç»“æœ")
                if loose_results:
                    scores = [score for _, score in loose_results]
                    logger.info(f"    ç›¸ä¼¼åº¦èŒƒå›´: {min(scores):.4f} ~ {max(scores):.4f}")
        
        except Exception as e:
            logger.error(f"  âŒ æŸ¥è¯¢å¤±è´¥: {type(e).__name__}: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
    
    logger.info("\n" + "=" * 60)
    logger.info("âœ… æµ‹è¯•å®Œæˆ")
    logger.info("=" * 60)


async def test_metadata_query():
    """æµ‹è¯•å…ƒæ•°æ®æ•°æ®åº“æŸ¥è¯¢èƒ½åŠ›"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ” å…ƒæ•°æ®æ•°æ®åº“å†…å®¹æ£€æŸ¥")
    logger.info("=" * 60)
    
    indexer = IndexerService()
    await indexer._ensure_initialized()
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = await indexer.metadata_store.get_stats()
    logger.info(f"\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡:")
    logger.info(f"  - æ–‡æ¡£æ€»æ•°: {stats['total_documents']}")
    logger.info(f"  - åˆ†å—æ€»æ•°: {stats['total_chunks']}")
    logger.info(f"  - æ ‡ç­¾æ€»æ•°: {stats['total_tags']}")
    
    if stats['total_documents'] == 0:
        logger.error("âŒ å…ƒæ•°æ®æ•°æ®åº“ä¸ºç©ºï¼")
        return
    
    logger.info("\nâœ… å…ƒæ•°æ®æ•°æ®åº“æ£€æŸ¥å®Œæˆ")


if __name__ == "__main__":
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    asyncio.run(test_metadata_query())
    asyncio.run(test_local_retrieval())
