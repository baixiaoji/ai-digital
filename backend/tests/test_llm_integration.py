"""
æµ‹è¯• LLM é›†æˆåˆ°æ£€ç´¢ç³»ç»Ÿ
"""
import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from services.llm import LLMService
from models import SearchResult


async def test_llm_answer_generation():
    """æµ‹è¯• LLM ç­”æ¡ˆç”Ÿæˆ"""
    print("=" * 60)
    print("æµ‹è¯• LLM ç­”æ¡ˆç”ŸæˆåŠŸèƒ½")
    print("=" * 60)
    
    # åˆ›å»º LLM æœåŠ¡
    llm_service = LLMService()
    
    # æ¨¡æ‹Ÿæ£€ç´¢ç»“æœ
    query = "å¦‚ä½•ä½¿ç”¨ Python è¿›è¡Œæ•°æ®åˆ†æï¼Ÿ"
    
    local_results = [
        {
            "title": "Python æ•°æ®åˆ†æåŸºç¡€",
            "content": "ä½¿ç”¨ Pandas åº“è¿›è¡Œæ•°æ®å¤„ç†å’Œåˆ†æã€‚Pandas æä¾›äº† DataFrame å’Œ Series ä¸¤ç§ä¸»è¦çš„æ•°æ®ç»“æ„ï¼Œå¯ä»¥é«˜æ•ˆåœ°å¤„ç†è¡¨æ ¼æ•°æ®ã€‚å¸¸ç”¨æ“ä½œåŒ…æ‹¬æ•°æ®æ¸…æ´—ã€è¿‡æ»¤ã€åˆ†ç»„ã€èšåˆç­‰ã€‚",
            "file_path": "/path/to/note1.md",
            "score": 0.92
        },
        {
            "title": "æ•°æ®å¯è§†åŒ–æŠ€å·§",
            "content": "ä½¿ç”¨ Matplotlib å’Œ Seaborn è¿›è¡Œæ•°æ®å¯è§†åŒ–ã€‚Matplotlib æ˜¯æœ€åŸºç¡€çš„å¯è§†åŒ–åº“ï¼ŒSeaborn åœ¨æ­¤åŸºç¡€ä¸Šæä¾›äº†æ›´ç¾è§‚çš„é»˜è®¤æ ·å¼å’Œæ›´é«˜çº§çš„ç»Ÿè®¡å›¾è¡¨ã€‚",
            "file_path": "/path/to/note2.md",
            "score": 0.85
        }
    ]
    
    web_results = [
        {
            "title": "Python Data Analysis Tutorial",
            "content": "Learn data analysis with Python using NumPy, Pandas, and Matplotlib. NumPy provides efficient array operations, Pandas handles structured data, and Matplotlib creates visualizations.",
            "url": "https://example.com/tutorial",
            "score": 0.78
        }
    ]
    
    print(f"\nğŸ“ ç”¨æˆ·é—®é¢˜: {query}")
    print(f"\nğŸ“Š æ£€ç´¢ç»“æœç»Ÿè®¡:")
    print(f"  - æœ¬åœ°ç¬”è®°: {len(local_results)} æ¡")
    print(f"  - ç½‘ç»œèµ„æº: {len(web_results)} æ¡")
    
    print("\nğŸ¤– æ­£åœ¨ä½¿ç”¨ LLM ç”Ÿæˆç­”æ¡ˆ...")
    
    try:
        # ç”Ÿæˆç­”æ¡ˆ
        answer = await llm_service.generate_answer(query, local_results, web_results)
        
        print("\nâœ… ç­”æ¡ˆç”ŸæˆæˆåŠŸï¼\n")
        print("=" * 60)
        print("LLM ç”Ÿæˆçš„ç­”æ¡ˆ:")
        print("=" * 60)
        print(answer)
        print("=" * 60)
        
        # æ£€æŸ¥ç­”æ¡ˆè´¨é‡
        print("\nğŸ“‹ ç­”æ¡ˆè´¨é‡æ£€æŸ¥:")
        if len(answer) > 100:
            print("  âœ… ç­”æ¡ˆé•¿åº¦åˆé€‚")
        else:
            print("  âš ï¸ ç­”æ¡ˆå¯èƒ½è¿‡çŸ­")
        
        if "Pandas" in answer or "pandas" in answer:
            print("  âœ… ç­”æ¡ˆåŒ…å«å…³é”®æ¦‚å¿µ")
        else:
            print("  âš ï¸ ç­”æ¡ˆå¯èƒ½ç¼ºå°‘å…³é”®æ¦‚å¿µ")
        
        print("\nâœ… æµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        raise
    
    finally:
        await llm_service.close()


async def test_fallback_mechanism():
    """æµ‹è¯•é™çº§æœºåˆ¶"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•é™çº§æœºåˆ¶ï¼ˆæ¨¡æ‹Ÿ LLM å¤±è´¥ï¼‰")
    print("=" * 60)
    
    llm_service = LLMService()
    
    # ä½¿ç”¨æ— æ•ˆçš„ model è§¦å‘é”™è¯¯
    original_model = llm_service.model
    llm_service.model = "invalid-model-name"
    
    query = "æµ‹è¯•é™çº§æœºåˆ¶"
    local_results = [
        {
            "title": "æµ‹è¯•ç¬”è®°",
            "content": "è¿™æ˜¯ä¸€æ¡æµ‹è¯•ç¬”è®°å†…å®¹",
            "file_path": "/test.md",
            "score": 0.9
        }
    ]
    web_results = []
    
    try:
        answer = await llm_service.generate_answer(query, local_results, web_results)
        
        print("\nâœ… é™çº§æœºåˆ¶æ­£å¸¸å·¥ä½œ")
        print(f"\né™çº§ç­”æ¡ˆé¢„è§ˆ:\n{answer[:200]}...")
        
        if "æµ‹è¯•ç¬”è®°" in answer:
            print("\nâœ… é™çº§ç­”æ¡ˆåŒ…å«æ£€ç´¢ç»“æœ")
        else:
            print("\nâš ï¸ é™çº§ç­”æ¡ˆå¯èƒ½ä¸å®Œæ•´")
    
    except Exception as e:
        print(f"\nâŒ é™çº§æœºåˆ¶æµ‹è¯•å¤±è´¥: {str(e)}")
        raise
    
    finally:
        llm_service.model = original_model
        await llm_service.close()


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\nğŸš€ å¼€å§‹æµ‹è¯• LLM é›†æˆåŠŸèƒ½\n")
    
    # æµ‹è¯• 1: æ­£å¸¸ LLM ç­”æ¡ˆç”Ÿæˆ
    await test_llm_answer_generation()
    
    # æµ‹è¯• 2: é™çº§æœºåˆ¶
    await test_fallback_mechanism()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(main())
